{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91cfb4ee-ea8d-45f7-a457-886c0d4eae38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 22:45:03.276068: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-11 22:45:03.382609: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "import model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import datasets, layers, models, callbacks, regularizers\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1cdb72c-021f-4249-a58b-c2d1b156d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify number of epochs for the two models\n",
    "epochs_drop = 50\n",
    "epochs_l2 = 50\n",
    "\n",
    "# Specify K for K-fold cross validaton\n",
    "num_folds = 5\n",
    "df = num_folds-1\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=num_folds)\n",
    "\n",
    "# Specify batch size for training\n",
    "batch_size = 20\n",
    "\n",
    "# Specify confidence level ( < 1)\n",
    "cf_lvl = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fae9095-9818-42e1-a7ce-9f6340138c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels, test_images, test_labels, img_shape = util.get_images()\n",
    "\n",
    "X = np.concatenate((train_images, test_images), axis=0)\n",
    "y = np.concatenate((train_labels, test_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81bd046f-578c-4228-8a3b-ac59f2b50cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_drop(\n",
    "    filter_nos=[32, 32, 32],\n",
    "    filter_size=(3, 3),\n",
    "    dense_layers=[64],\n",
    "    input_shape=img_shape,\n",
    "    patience=5,\n",
    "    dropoutRate=0.1,\n",
    "    output_length=100\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        filter_nos (tuple): number of filters in each Conv2D layer\n",
    "        filter_size (tuple): size of Conv2D filters. Filters are assumed to have uniform sizes across layers.\n",
    "        input_shape (tuple): shape of the input of the first layer\n",
    "        dense_layer (tuple): number of hidden units in each Dense layer except the output layer. Output layer is hardcoded to the number of classes.\n",
    "        patience (integer): number of epochs of no improvement until early stop triggers.\n",
    "        dropoutRate (double < 1): rate of value drop\n",
    "        output_length (integer): number of classes for output\n",
    "    \"\"\"\n",
    "    # Would include a dropout parameter, but wasn't absolutely sure where those would be, though I would assume closer to the start.\n",
    "\n",
    "    model = models.Sequential()\n",
    "    callback = callbacks.EarlyStopping(monitor='loss',patience=patience) # EarlyStopping \n",
    "\n",
    "    for i, filter_no in enumerate(filter_nos):\n",
    "        if i == 0:\n",
    "            # first Conv2D requires input_shape\n",
    "            model.add(\n",
    "                layers.Conv2D(\n",
    "                    filter_no, filter_size, activation=\"relu\", input_shape=input_shape, kernel_regularizer='l2'\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            model.add(layers.Conv2D(filter_no, filter_size, activation=\"relu\"))\n",
    "\n",
    "        if i + 1 < len(filter_nos):\n",
    "            model.add(\n",
    "                layers.MaxPooling2D((2, 2))\n",
    "            )  # add MaxPooling layer to all but the last convolutional stack\n",
    "            model.add(\n",
    "                layers.Dropout(rate=dropoutRate)\n",
    "            )  \n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    for dense_layer in dense_layers:\n",
    "        model.add(layers.Dense(dense_layer, activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.Dense(output_length))  # output layer\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a7e80c8-4e1b-4815-8903-c10834653976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_l2(\n",
    "    filter_nos=[32, 32, 32],\n",
    "    filter_size=(3, 3),\n",
    "    dense_layers=[64],\n",
    "    input_shape=img_shape,\n",
    "    patience=5,\n",
    "    l2param=0.1,\n",
    "    output_length=100\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        filter_nos (tuple): number of filters in each Conv2D layer\n",
    "        filter_size (tuple): size of Conv2D filters. Filters are assumed to have uniform sizes across layers.\n",
    "        input_shape (tuple): shape of the input of the first layer\n",
    "        dense_layer (tuple): number of hidden units in each Dense layer except the output layer. Output layer is hardcoded to the number of classes.\n",
    "        patience (integer): number of epochs of no improvement until early stop triggers.\n",
    "        l2param (double < 1): param given to L2\n",
    "        output_length (integer): number of classes given to output\n",
    "    \"\"\"\n",
    "    # Would include a dropout parameter, but wasn't absolutely sure where those would be, though I would assume closer to the start.\n",
    "\n",
    "    model = models.Sequential()\n",
    "    regularizers.L2(l2=l2param) #L2\n",
    "    callback = callbacks.EarlyStopping(monitor='loss',patience=patience) # EarlyStopping \n",
    "\n",
    "    for i, filter_no in enumerate(filter_nos):\n",
    "        if i == 0:\n",
    "            # first Conv2D requires input_shape\n",
    "            model.add(\n",
    "                layers.Conv2D(\n",
    "                    filter_no, filter_size, activation=\"relu\", input_shape=input_shape, kernel_regularizer='l2'\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            model.add(layers.Conv2D(filter_no, filter_size, activation=\"relu\", kernel_regularizer='l2'))\n",
    "\n",
    "        if i + 1 < len(filter_nos):\n",
    "            model.add(\n",
    "                layers.MaxPooling2D((2, 2))\n",
    "            )  # add MaxPooling layer to all but the last convolutional stack\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    for dense_layer in dense_layers:\n",
    "        model.add(layers.Dense(dense_layer, activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.Dense(output_length))  # output layer\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "793f5d29-2a4d-4899-aa71-9122eec18e89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stopper = callbacks.EarlyStopping(monitor='val_accuracy', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "260b5eac-72df-40be-b78b-201cd3037a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropoff\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 22:45:11.764910: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2024-07-11 22:45:11.805798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.74GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-07-11 22:45:11.805824: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-11 22:45:11.848561: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-11 22:45:11.870557: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-11 22:45:11.877647: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-11 22:45:11.914753: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-11 22:45:11.922772: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-11 22:45:11.995609: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-11 22:45:11.996035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a6669dbc10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a6669dbc10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 22:45:11.998100: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-11 22:45:12.012929: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz\n",
      "2024-07-11 22:45:12.013028: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560314799980 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-11 22:45:12.013036: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-07-11 22:45:12.014166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.74GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-07-11 22:45:12.014193: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-11 22:45:12.014213: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-11 22:45:12.014221: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-11 22:45:12.014230: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-11 22:45:12.014238: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-11 22:45:12.014246: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-11 22:45:12.014254: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-11 22:45:12.014552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-07-11 22:45:13.043572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-07-11 22:45:13.043600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2024-07-11 22:45:13.043605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2024-07-11 22:45:13.044661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30131 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0)\n",
      "2024-07-11 22:45:13.048063: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5603416c74b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-11 22:45:13.048078: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2024-07-11 22:45:14.697431: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-11 22:45:15.059484: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2378/2400 [============================>.] - ETA: 0s - loss: 4.0702 - accuracy: 0.0772WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a6668a2280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a6668a2280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2400/2400 [==============================] - 5s 2ms/step - loss: 4.0671 - accuracy: 0.0776 - val_loss: 3.6961 - val_accuracy: 0.1312\n",
      "Epoch 2/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.5080 - accuracy: 0.1670 - val_loss: 3.3704 - val_accuracy: 0.1902\n",
      "Epoch 3/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.2330 - accuracy: 0.2162 - val_loss: 3.1957 - val_accuracy: 0.2208\n",
      "Epoch 4/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0671 - accuracy: 0.2508 - val_loss: 3.0875 - val_accuracy: 0.2478\n",
      "Epoch 5/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.9515 - accuracy: 0.2737 - val_loss: 2.9677 - val_accuracy: 0.2698\n",
      "Epoch 6/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.8653 - accuracy: 0.2922 - val_loss: 2.9231 - val_accuracy: 0.2773\n",
      "Epoch 7/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.7955 - accuracy: 0.3026 - val_loss: 2.9009 - val_accuracy: 0.2856\n",
      "Epoch 8/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.7320 - accuracy: 0.3173 - val_loss: 2.8817 - val_accuracy: 0.2861\n",
      "Epoch 9/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.6767 - accuracy: 0.3276 - val_loss: 2.8374 - val_accuracy: 0.3006\n",
      "Epoch 10/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.6294 - accuracy: 0.3353 - val_loss: 2.8274 - val_accuracy: 0.3007\n",
      "Epoch 11/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.5875 - accuracy: 0.3461 - val_loss: 2.8892 - val_accuracy: 0.2948\n",
      "Epoch 12/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.5482 - accuracy: 0.3538 - val_loss: 2.8058 - val_accuracy: 0.3130\n",
      "Epoch 13/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.5165 - accuracy: 0.3619 - val_loss: 2.8105 - val_accuracy: 0.3128\n",
      "Epoch 14/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.4903 - accuracy: 0.3653 - val_loss: 2.8019 - val_accuracy: 0.3132\n",
      "Epoch 15/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.4554 - accuracy: 0.3752 - val_loss: 2.8182 - val_accuracy: 0.3118\n",
      "Epoch 16/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.4334 - accuracy: 0.3789 - val_loss: 2.7461 - val_accuracy: 0.3250\n",
      "Epoch 17/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.4027 - accuracy: 0.3854 - val_loss: 2.7760 - val_accuracy: 0.3231\n",
      "Epoch 18/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3896 - accuracy: 0.3876 - val_loss: 2.8050 - val_accuracy: 0.3213\n",
      "Epoch 19/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3635 - accuracy: 0.3919 - val_loss: 2.7802 - val_accuracy: 0.3228\n",
      "Epoch 20/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3467 - accuracy: 0.3977 - val_loss: 2.7302 - val_accuracy: 0.3327\n",
      "Epoch 21/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3339 - accuracy: 0.3998 - val_loss: 2.7695 - val_accuracy: 0.3271\n",
      "Epoch 22/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3211 - accuracy: 0.4043 - val_loss: 2.7669 - val_accuracy: 0.3323\n",
      "Epoch 23/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3055 - accuracy: 0.4035 - val_loss: 2.7813 - val_accuracy: 0.3234\n",
      "Epoch 24/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.2914 - accuracy: 0.4090 - val_loss: 2.7902 - val_accuracy: 0.3264\n",
      "Epoch 25/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.2778 - accuracy: 0.4114 - val_loss: 2.7528 - val_accuracy: 0.3277\n",
      "375/375 - 0s - loss: 2.7528 - accuracy: 0.3277\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a65434a820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a65434a820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2391/2400 [============================>.] - ETA: 0s - loss: 4.1186 - accuracy: 0.0663WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a5540a9f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a5540a9f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.1173 - accuracy: 0.0666 - val_loss: 3.7954 - val_accuracy: 0.1187\n",
      "Epoch 2/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.5972 - accuracy: 0.1507 - val_loss: 3.4618 - val_accuracy: 0.1691\n",
      "Epoch 3/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.3396 - accuracy: 0.1953 - val_loss: 3.2931 - val_accuracy: 0.2057\n",
      "Epoch 4/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.1811 - accuracy: 0.2256 - val_loss: 3.1844 - val_accuracy: 0.2253\n",
      "Epoch 5/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0533 - accuracy: 0.2480 - val_loss: 3.0621 - val_accuracy: 0.2497\n",
      "Epoch 6/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.9575 - accuracy: 0.2695 - val_loss: 2.9837 - val_accuracy: 0.2677\n",
      "Epoch 7/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.8782 - accuracy: 0.2829 - val_loss: 2.9436 - val_accuracy: 0.2700\n",
      "Epoch 8/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.8062 - accuracy: 0.2979 - val_loss: 2.8843 - val_accuracy: 0.2862\n",
      "Epoch 9/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.7468 - accuracy: 0.3080 - val_loss: 2.8253 - val_accuracy: 0.2982\n",
      "Epoch 10/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.6992 - accuracy: 0.3200 - val_loss: 2.7918 - val_accuracy: 0.3064\n",
      "Epoch 11/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.6508 - accuracy: 0.3301 - val_loss: 2.8094 - val_accuracy: 0.3027\n",
      "Epoch 12/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.6129 - accuracy: 0.3366 - val_loss: 2.8145 - val_accuracy: 0.3089\n",
      "Epoch 13/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.5828 - accuracy: 0.3428 - val_loss: 2.7671 - val_accuracy: 0.3119\n",
      "Epoch 14/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.5486 - accuracy: 0.3519 - val_loss: 2.7619 - val_accuracy: 0.3178\n",
      "Epoch 15/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.5175 - accuracy: 0.3577 - val_loss: 2.7352 - val_accuracy: 0.3227\n",
      "Epoch 16/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.5029 - accuracy: 0.3619 - val_loss: 2.7754 - val_accuracy: 0.3200\n",
      "Epoch 17/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.4671 - accuracy: 0.3688 - val_loss: 2.7714 - val_accuracy: 0.3247\n",
      "Epoch 18/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.4490 - accuracy: 0.3722 - val_loss: 2.7491 - val_accuracy: 0.3256\n",
      "Epoch 19/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.4330 - accuracy: 0.3747 - val_loss: 2.7295 - val_accuracy: 0.3267\n",
      "Epoch 20/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.4168 - accuracy: 0.3772 - val_loss: 2.7370 - val_accuracy: 0.3303\n",
      "Epoch 21/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3957 - accuracy: 0.3835 - val_loss: 2.7507 - val_accuracy: 0.3293\n",
      "Epoch 22/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3767 - accuracy: 0.3856 - val_loss: 2.7748 - val_accuracy: 0.3253\n",
      "Epoch 23/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3538 - accuracy: 0.3917 - val_loss: 2.7333 - val_accuracy: 0.3322\n",
      "Epoch 24/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3481 - accuracy: 0.3912 - val_loss: 2.8312 - val_accuracy: 0.3162\n",
      "Epoch 25/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3300 - accuracy: 0.3954 - val_loss: 2.7874 - val_accuracy: 0.3192\n",
      "Epoch 26/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3204 - accuracy: 0.3985 - val_loss: 2.7516 - val_accuracy: 0.3313\n",
      "Epoch 27/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3117 - accuracy: 0.3994 - val_loss: 2.7417 - val_accuracy: 0.3299\n",
      "Epoch 28/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.2941 - accuracy: 0.4037 - val_loss: 2.7118 - val_accuracy: 0.3372\n",
      "Epoch 29/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.2825 - accuracy: 0.4054 - val_loss: 2.7447 - val_accuracy: 0.3279\n",
      "Epoch 30/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.2704 - accuracy: 0.4063 - val_loss: 2.7526 - val_accuracy: 0.3315\n",
      "Epoch 31/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.2622 - accuracy: 0.4063 - val_loss: 2.7778 - val_accuracy: 0.3298\n",
      "Epoch 32/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.2600 - accuracy: 0.4090 - val_loss: 2.7732 - val_accuracy: 0.3300\n",
      "Epoch 33/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.2388 - accuracy: 0.4140 - val_loss: 2.7426 - val_accuracy: 0.3367\n",
      "375/375 - 0s - loss: 2.7426 - accuracy: 0.3367\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a666a8fd30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a666a8fd30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2375/2400 [============================>.] - ETA: 0s - loss: 4.1159 - accuracy: 0.0698WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a6668c4940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a6668c4940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.1126 - accuracy: 0.0702 - val_loss: 3.7272 - val_accuracy: 0.1253\n",
      "Epoch 2/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.5715 - accuracy: 0.1550 - val_loss: 3.4483 - val_accuracy: 0.1745\n",
      "Epoch 3/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.3132 - accuracy: 0.2006 - val_loss: 3.2266 - val_accuracy: 0.2148\n",
      "Epoch 4/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.1613 - accuracy: 0.2286 - val_loss: 3.1385 - val_accuracy: 0.2369\n",
      "Epoch 5/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0445 - accuracy: 0.2519 - val_loss: 3.1103 - val_accuracy: 0.2484\n",
      "Epoch 6/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.9548 - accuracy: 0.2691 - val_loss: 2.9523 - val_accuracy: 0.2793\n",
      "Epoch 7/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.8771 - accuracy: 0.2878 - val_loss: 2.9004 - val_accuracy: 0.2873\n",
      "Epoch 8/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.8181 - accuracy: 0.2991 - val_loss: 2.8793 - val_accuracy: 0.2824\n",
      "Epoch 9/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.7589 - accuracy: 0.3088 - val_loss: 2.8591 - val_accuracy: 0.2976\n",
      "Epoch 10/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.7116 - accuracy: 0.3165 - val_loss: 2.8066 - val_accuracy: 0.3086\n",
      "Epoch 11/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.6762 - accuracy: 0.3249 - val_loss: 2.7765 - val_accuracy: 0.3181\n",
      "Epoch 12/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.6276 - accuracy: 0.3373 - val_loss: 2.8046 - val_accuracy: 0.3098\n",
      "Epoch 13/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.5927 - accuracy: 0.3426 - val_loss: 2.7744 - val_accuracy: 0.3120\n",
      "Epoch 14/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.5667 - accuracy: 0.3491 - val_loss: 2.7417 - val_accuracy: 0.3307\n",
      "Epoch 15/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.5370 - accuracy: 0.3537 - val_loss: 2.7190 - val_accuracy: 0.3270\n",
      "Epoch 16/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.5108 - accuracy: 0.3585 - val_loss: 2.7625 - val_accuracy: 0.3181\n",
      "Epoch 17/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.4887 - accuracy: 0.3619 - val_loss: 2.7476 - val_accuracy: 0.3273\n",
      "Epoch 18/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.4663 - accuracy: 0.3695 - val_loss: 2.7534 - val_accuracy: 0.3191\n",
      "Epoch 19/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.4445 - accuracy: 0.3713 - val_loss: 2.7952 - val_accuracy: 0.3249\n",
      "375/375 - 0s - loss: 2.7952 - accuracy: 0.3249\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a6668a2940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a6668a2940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2397/2400 [============================>.] - ETA: 0s - loss: 4.0523 - accuracy: 0.0790WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a5457e2a60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a5457e2a60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.0524 - accuracy: 0.0790 - val_loss: 3.7049 - val_accuracy: 0.1271\n",
      "Epoch 2/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.4904 - accuracy: 0.1711 - val_loss: 3.3147 - val_accuracy: 0.2012\n",
      "Epoch 3/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.2122 - accuracy: 0.2208 - val_loss: 3.1807 - val_accuracy: 0.2228\n",
      "Epoch 4/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0395 - accuracy: 0.2535 - val_loss: 3.0303 - val_accuracy: 0.2573\n",
      "Epoch 5/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.9142 - accuracy: 0.2798 - val_loss: 2.9363 - val_accuracy: 0.2793\n",
      "Epoch 6/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.8219 - accuracy: 0.2969 - val_loss: 2.8929 - val_accuracy: 0.2867\n",
      "Epoch 7/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.7495 - accuracy: 0.3133 - val_loss: 2.8388 - val_accuracy: 0.3043\n",
      "Epoch 8/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.6878 - accuracy: 0.3225 - val_loss: 2.8625 - val_accuracy: 0.2981\n",
      "Epoch 9/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.6318 - accuracy: 0.3368 - val_loss: 2.7976 - val_accuracy: 0.3126\n",
      "Epoch 10/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.5852 - accuracy: 0.3426 - val_loss: 2.8015 - val_accuracy: 0.3112\n",
      "Epoch 11/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.5389 - accuracy: 0.3568 - val_loss: 2.7804 - val_accuracy: 0.3199\n",
      "Epoch 12/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.5064 - accuracy: 0.3606 - val_loss: 2.7398 - val_accuracy: 0.3233\n",
      "Epoch 13/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.4605 - accuracy: 0.3713 - val_loss: 2.7067 - val_accuracy: 0.3294\n",
      "Epoch 14/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.4383 - accuracy: 0.3750 - val_loss: 2.7267 - val_accuracy: 0.3323\n",
      "Epoch 15/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.4005 - accuracy: 0.3847 - val_loss: 2.6711 - val_accuracy: 0.3417\n",
      "Epoch 16/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3753 - accuracy: 0.3886 - val_loss: 2.6957 - val_accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3585 - accuracy: 0.3911 - val_loss: 2.7443 - val_accuracy: 0.3275\n",
      "Epoch 18/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3293 - accuracy: 0.3982 - val_loss: 2.7262 - val_accuracy: 0.3383\n",
      "Epoch 19/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3090 - accuracy: 0.4028 - val_loss: 2.6934 - val_accuracy: 0.3415\n",
      "Epoch 20/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.2943 - accuracy: 0.4058 - val_loss: 2.7304 - val_accuracy: 0.3377\n",
      "375/375 - 0s - loss: 2.7304 - accuracy: 0.3377\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a5457acee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a5457acee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 4.0708 - accuracy: 0.0755WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a54502b550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a54502b550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.0655 - accuracy: 0.0763 - val_loss: 3.7019 - val_accuracy: 0.1288\n",
      "Epoch 2/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.5063 - accuracy: 0.1665 - val_loss: 3.3268 - val_accuracy: 0.2028\n",
      "Epoch 3/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.2205 - accuracy: 0.2166 - val_loss: 3.1598 - val_accuracy: 0.2311\n",
      "Epoch 4/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0444 - accuracy: 0.2521 - val_loss: 2.9830 - val_accuracy: 0.2679\n",
      "Epoch 5/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.9222 - accuracy: 0.2753 - val_loss: 2.9179 - val_accuracy: 0.2833\n",
      "Epoch 6/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.8260 - accuracy: 0.2926 - val_loss: 2.9331 - val_accuracy: 0.2808\n",
      "Epoch 7/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.7558 - accuracy: 0.3092 - val_loss: 2.8588 - val_accuracy: 0.2970\n",
      "Epoch 8/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.6941 - accuracy: 0.3220 - val_loss: 2.7760 - val_accuracy: 0.3141\n",
      "Epoch 9/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.6397 - accuracy: 0.3306 - val_loss: 2.7688 - val_accuracy: 0.3108\n",
      "Epoch 10/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.5992 - accuracy: 0.3402 - val_loss: 2.7822 - val_accuracy: 0.3122\n",
      "Epoch 11/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.5552 - accuracy: 0.3526 - val_loss: 2.7472 - val_accuracy: 0.3174\n",
      "Epoch 12/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.5198 - accuracy: 0.3560 - val_loss: 2.7028 - val_accuracy: 0.3295\n",
      "Epoch 13/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.4865 - accuracy: 0.3618 - val_loss: 2.7104 - val_accuracy: 0.3288\n",
      "Epoch 14/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.4500 - accuracy: 0.3721 - val_loss: 2.7171 - val_accuracy: 0.3227\n",
      "Epoch 15/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.4296 - accuracy: 0.3767 - val_loss: 2.7134 - val_accuracy: 0.3310\n",
      "Epoch 16/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.4044 - accuracy: 0.3823 - val_loss: 2.6770 - val_accuracy: 0.3361\n",
      "Epoch 17/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3852 - accuracy: 0.3866 - val_loss: 2.7397 - val_accuracy: 0.3278\n",
      "Epoch 18/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3557 - accuracy: 0.3905 - val_loss: 2.6738 - val_accuracy: 0.3384\n",
      "Epoch 19/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3327 - accuracy: 0.3989 - val_loss: 2.8085 - val_accuracy: 0.3224\n",
      "Epoch 20/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3236 - accuracy: 0.3950 - val_loss: 2.8706 - val_accuracy: 0.3171\n",
      "Epoch 21/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.3022 - accuracy: 0.4041 - val_loss: 2.7275 - val_accuracy: 0.3300\n",
      "Epoch 22/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.2877 - accuracy: 0.4061 - val_loss: 2.7430 - val_accuracy: 0.3296\n",
      "Epoch 23/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.2744 - accuracy: 0.4111 - val_loss: 2.6944 - val_accuracy: 0.3364\n",
      "375/375 - 0s - loss: 2.6944 - accuracy: 0.3364\n",
      "\n",
      "\n",
      "drop model accuracy and loss:\n",
      "[0.32766667008399963, 0.33666667342185974, 0.32491666078567505, 0.33766666054725647, 0.33641666173934937]\n",
      "[2.7528319358825684, 2.7425696849823, 2.7952401638031006, 2.7303545475006104, 2.6944422721862793]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dropoff\\n\")\n",
    "\n",
    "drop_acc = []\n",
    "drop_loss = [] \n",
    "\n",
    "for train, test in kfold.split(X,y):\n",
    "    model_drop = create_model_drop(\n",
    "        filter_nos=(32, 64, 64),\n",
    "        filter_size=(3,3),\n",
    "        dense_layers=(64,),\n",
    "        input_shape=img_shape,\n",
    "        patience=5,\n",
    "        dropoutRate=0.1,\n",
    "        output_length=100\n",
    "    )\n",
    "\n",
    "    history_drop = model_drop.fit(\n",
    "        X[train], y[train], epochs=epochs_drop, batch_size=batch_size, callbacks=[stopper], validation_data=(X[test], y[test])\n",
    "    )\n",
    "\n",
    "    test_loss, test_acc = model_drop.evaluate(X[test], y[test], verbose=2)\n",
    "    drop_loss.append(test_loss)\n",
    "    drop_acc.append(test_acc)\n",
    "\n",
    "print(\"\\n\\ndrop model accuracy and loss:\")\n",
    "print(drop_acc)\n",
    "print(drop_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "602d2cd2-0948-40a2-ae78-41fc2a744971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a5448bb040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a5448bb040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2391/2400 [============================>.] - ETA: 0s - loss: 4.2337 - accuracy: 0.0489WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a5448648b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a5448648b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.2331 - accuracy: 0.0490 - val_loss: 4.0206 - val_accuracy: 0.0783\n",
      "Epoch 2/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.9131 - accuracy: 0.0992 - val_loss: 3.8796 - val_accuracy: 0.1122\n",
      "Epoch 3/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.7825 - accuracy: 0.1283 - val_loss: 3.7392 - val_accuracy: 0.1373\n",
      "Epoch 4/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.6832 - accuracy: 0.1488 - val_loss: 3.6543 - val_accuracy: 0.1534\n",
      "Epoch 5/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.6059 - accuracy: 0.1624 - val_loss: 3.6377 - val_accuracy: 0.1570\n",
      "Epoch 6/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.5465 - accuracy: 0.1721 - val_loss: 3.5705 - val_accuracy: 0.1733\n",
      "Epoch 7/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.4887 - accuracy: 0.1862 - val_loss: 3.5194 - val_accuracy: 0.1828\n",
      "Epoch 8/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.4389 - accuracy: 0.1965 - val_loss: 3.4416 - val_accuracy: 0.1992\n",
      "Epoch 9/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.3919 - accuracy: 0.2025 - val_loss: 3.4553 - val_accuracy: 0.1883\n",
      "Epoch 10/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.3493 - accuracy: 0.2129 - val_loss: 3.3625 - val_accuracy: 0.2056\n",
      "Epoch 11/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.3124 - accuracy: 0.2215 - val_loss: 3.3491 - val_accuracy: 0.2113\n",
      "Epoch 12/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.2820 - accuracy: 0.2262 - val_loss: 3.3237 - val_accuracy: 0.2211\n",
      "Epoch 13/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.2518 - accuracy: 0.2324 - val_loss: 3.3763 - val_accuracy: 0.2119\n",
      "Epoch 14/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.2282 - accuracy: 0.2352 - val_loss: 3.2771 - val_accuracy: 0.2311\n",
      "Epoch 15/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.2050 - accuracy: 0.2410 - val_loss: 3.2361 - val_accuracy: 0.2377\n",
      "Epoch 16/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.1840 - accuracy: 0.2455 - val_loss: 3.2420 - val_accuracy: 0.2352\n",
      "Epoch 17/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.1637 - accuracy: 0.2509 - val_loss: 3.2379 - val_accuracy: 0.2340\n",
      "Epoch 18/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.1484 - accuracy: 0.2530 - val_loss: 3.1793 - val_accuracy: 0.2512\n",
      "Epoch 19/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.1274 - accuracy: 0.2582 - val_loss: 3.1956 - val_accuracy: 0.2429\n",
      "Epoch 20/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.1160 - accuracy: 0.2587 - val_loss: 3.1660 - val_accuracy: 0.2497\n",
      "Epoch 21/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.1040 - accuracy: 0.2605 - val_loss: 3.1784 - val_accuracy: 0.2491\n",
      "Epoch 22/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0888 - accuracy: 0.2640 - val_loss: 3.1859 - val_accuracy: 0.2517\n",
      "Epoch 23/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0808 - accuracy: 0.2655 - val_loss: 3.1515 - val_accuracy: 0.2564\n",
      "Epoch 24/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0716 - accuracy: 0.2690 - val_loss: 3.1804 - val_accuracy: 0.2503\n",
      "Epoch 25/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0614 - accuracy: 0.2694 - val_loss: 3.1260 - val_accuracy: 0.2629\n",
      "Epoch 26/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0520 - accuracy: 0.2740 - val_loss: 3.1536 - val_accuracy: 0.2533\n",
      "Epoch 27/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0476 - accuracy: 0.2708 - val_loss: 3.1643 - val_accuracy: 0.2556\n",
      "Epoch 28/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0385 - accuracy: 0.2753 - val_loss: 3.1626 - val_accuracy: 0.2550\n",
      "Epoch 29/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0371 - accuracy: 0.2741 - val_loss: 3.1341 - val_accuracy: 0.2635\n",
      "Epoch 30/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0261 - accuracy: 0.2805 - val_loss: 3.1296 - val_accuracy: 0.2653\n",
      "Epoch 31/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0203 - accuracy: 0.2800 - val_loss: 3.1056 - val_accuracy: 0.2621\n",
      "Epoch 32/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0165 - accuracy: 0.2790 - val_loss: 3.1791 - val_accuracy: 0.2534\n",
      "Epoch 33/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0109 - accuracy: 0.2807 - val_loss: 3.1280 - val_accuracy: 0.2615\n",
      "Epoch 34/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0063 - accuracy: 0.2810 - val_loss: 3.1733 - val_accuracy: 0.2510\n",
      "Epoch 35/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0001 - accuracy: 0.2838 - val_loss: 3.1305 - val_accuracy: 0.2631\n",
      "375/375 - 0s - loss: 2.0691 - accuracy: 0.4493\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a544829f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a544829f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2382/2400 [============================>.] - ETA: 0s - loss: 4.6202 - accuracy: 0.0089WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a54472a9d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a54472a9d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.6201 - accuracy: 0.0090 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
      "Epoch 2/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.6061 - accuracy: 0.0088 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
      "Epoch 3/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.6061 - accuracy: 0.0095 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
      "Epoch 4/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.6061 - accuracy: 0.0085 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
      "Epoch 5/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.6061 - accuracy: 0.0091 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
      "Epoch 6/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.6061 - accuracy: 0.0084 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
      "375/375 - 0s - loss: 2.0607 - accuracy: 0.4530\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a5446f7670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a5446f7670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2381/2400 [============================>.] - ETA: 0s - loss: 4.6199 - accuracy: 0.0091WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a54502b280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a54502b280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2400/2400 [==============================] - 5s 2ms/step - loss: 4.6198 - accuracy: 0.0090 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
      "Epoch 2/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.6061 - accuracy: 0.0089 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
      "Epoch 3/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.6061 - accuracy: 0.0085 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
      "Epoch 4/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.6061 - accuracy: 0.0086 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
      "Epoch 5/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.6061 - accuracy: 0.0097 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
      "Epoch 6/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.6061 - accuracy: 0.0093 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
      "375/375 - 0s - loss: 2.0701 - accuracy: 0.4541\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a5448bbaf0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a5448bbaf0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2386/2400 [============================>.] - ETA: 0s - loss: 4.6204 - accuracy: 0.0087WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a5457ac820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a5457ac820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.6203 - accuracy: 0.0086 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
      "Epoch 2/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.6062 - accuracy: 0.0096 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
      "Epoch 3/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.6061 - accuracy: 0.0094 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
      "Epoch 4/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.6061 - accuracy: 0.0090 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
      "Epoch 5/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.6061 - accuracy: 0.0090 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
      "Epoch 6/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.6061 - accuracy: 0.0086 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
      "375/375 - 0s - loss: 2.0734 - accuracy: 0.4530\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a66690c940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14a66690c940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2398/2400 [============================>.] - ETA: 0s - loss: 4.2578 - accuracy: 0.0474WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a6668a2ee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14a6668a2ee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 4.2576 - accuracy: 0.0475 - val_loss: 4.0196 - val_accuracy: 0.0797\n",
      "Epoch 2/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.9312 - accuracy: 0.0988 - val_loss: 3.8823 - val_accuracy: 0.1140\n",
      "Epoch 3/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.7518 - accuracy: 0.1342 - val_loss: 3.6667 - val_accuracy: 0.1517\n",
      "Epoch 4/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.6099 - accuracy: 0.1627 - val_loss: 3.5985 - val_accuracy: 0.1708\n",
      "Epoch 5/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.5059 - accuracy: 0.1821 - val_loss: 3.4730 - val_accuracy: 0.1916\n",
      "Epoch 6/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.4198 - accuracy: 0.1990 - val_loss: 3.4207 - val_accuracy: 0.2003\n",
      "Epoch 7/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.3598 - accuracy: 0.2097 - val_loss: 3.3707 - val_accuracy: 0.2078\n",
      "Epoch 8/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.3117 - accuracy: 0.2223 - val_loss: 3.3509 - val_accuracy: 0.2172\n",
      "Epoch 9/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.2710 - accuracy: 0.2296 - val_loss: 3.3798 - val_accuracy: 0.2132\n",
      "Epoch 10/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.2387 - accuracy: 0.2377 - val_loss: 3.2547 - val_accuracy: 0.2348\n",
      "Epoch 11/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.2089 - accuracy: 0.2419 - val_loss: 3.2674 - val_accuracy: 0.2386\n",
      "Epoch 12/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.1844 - accuracy: 0.2475 - val_loss: 3.2247 - val_accuracy: 0.2444\n",
      "Epoch 13/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.1602 - accuracy: 0.2513 - val_loss: 3.1926 - val_accuracy: 0.2549\n",
      "Epoch 14/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.1371 - accuracy: 0.2582 - val_loss: 3.1880 - val_accuracy: 0.2507\n",
      "Epoch 15/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.1125 - accuracy: 0.2631 - val_loss: 3.1380 - val_accuracy: 0.2659\n",
      "Epoch 16/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0959 - accuracy: 0.2687 - val_loss: 3.1495 - val_accuracy: 0.2640\n",
      "Epoch 17/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0755 - accuracy: 0.2699 - val_loss: 3.2419 - val_accuracy: 0.2477\n",
      "Epoch 18/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0598 - accuracy: 0.2741 - val_loss: 3.1487 - val_accuracy: 0.2612\n",
      "Epoch 19/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0460 - accuracy: 0.2760 - val_loss: 3.0796 - val_accuracy: 0.2754\n",
      "Epoch 20/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0309 - accuracy: 0.2786 - val_loss: 3.0770 - val_accuracy: 0.2814\n",
      "Epoch 21/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0208 - accuracy: 0.2819 - val_loss: 3.1272 - val_accuracy: 0.2664\n",
      "Epoch 22/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 3.0056 - accuracy: 0.2860 - val_loss: 3.1050 - val_accuracy: 0.2702\n",
      "Epoch 23/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.9947 - accuracy: 0.2881 - val_loss: 3.0694 - val_accuracy: 0.2743\n",
      "Epoch 24/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.9830 - accuracy: 0.2893 - val_loss: 3.1197 - val_accuracy: 0.2724\n",
      "Epoch 25/50\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 2.9763 - accuracy: 0.2913 - val_loss: 3.0780 - val_accuracy: 0.2793\n",
      "375/375 - 0s - loss: 2.6944 - accuracy: 0.3364\n",
      "\n",
      "l2 model accuracy and loss:\n",
      "[0.4493333399295807, 0.453000009059906, 0.45408332347869873, 0.453000009059906, 0.33641666173934937]\n",
      "[2.069110631942749, 2.0607008934020996, 2.0701229572296143, 2.073361873626709, 2.6944422721862793]\n"
     ]
    }
   ],
   "source": [
    "print(\"L2\\n\")\n",
    "#classifier_l2 = KerasClassifier(\n",
    "#    create_model_l2,\n",
    "#    filter_nos=(32, 64, 64),\n",
    "#    filter_size=(3, 3),\n",
    "#    dense_layers=(64,),\n",
    "#    input_shape=image_shape,\n",
    "#    patience=5,\n",
    "#    l2param=0.01,\n",
    "#    output_length=100,\n",
    "#    epochs=epochs_l2,\n",
    "#    batch_size=32,\n",
    "#)\n",
    "\n",
    "#l2Scores = dropScores = cross_validate(\n",
    "#    estimator=classifier_l2, X=train_images, y=train_labels, cv=num_folds, scoring=make_scorer(accuracy_score)\n",
    "#)\n",
    "\n",
    "l2_acc = []\n",
    "l2_loss = []\n",
    "\n",
    "for train, test in kfold.split(X,y):\n",
    "    model_l2 = create_model_l2(\n",
    "        filter_nos=(32, 64, 64),\n",
    "        filter_size=(3, 3),\n",
    "        dense_layers=(64,),\n",
    "        input_shape=img_shape,\n",
    "        patience=5,\n",
    "        l2param=1e-4,\n",
    "        output_length=100\n",
    "    )\n",
    "\n",
    "    history_l2 = model_l2.fit(\n",
    "        X[train], y[train], epochs=epochs_drop, batch_size=batch_size, callbacks=[stopper], validation_data=(X[test], y[test])\n",
    "    )\n",
    "\n",
    "    test_loss, test_acc = model_drop.evaluate(X[test], y[test], verbose=2)\n",
    "    l2_loss.append(test_loss)\n",
    "    l2_acc.append(test_acc)\n",
    "\n",
    "print(\"\\nl2 model accuracy and loss:\")\n",
    "print(l2_acc)\n",
    "print(l2_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d420746-bf13-407b-adf6-afee19d10107",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = util.diff_scores(drop_acc, l2_acc)\n",
    "mean_diff = np.mean(diff)\n",
    "std_diff = np.std(diff, ddof=df)\n",
    "cf_interval = t.interval(cf_lvl, df, loc=mean_diff, scale=std_diff/np.sqrt(num_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f5e03f4-9876-414f-a32d-e47f504eea1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confidence Interval = (-0.23115489084203783, 0.038154884166317626)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nConfidence Interval = {cf_interval}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python CSE478",
   "language": "python",
   "name": "cse478-hw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
