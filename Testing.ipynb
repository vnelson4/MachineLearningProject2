{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91cfb4ee-ea8d-45f7-a457-886c0d4eae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import model\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from tensorflow.keras import datasets, layers, models, callbacks, regularizers\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1cdb72c-021f-4249-a58b-c2d1b156d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify number of epochs for the two models\n",
    "epochs_drop = 10\n",
    "epochs_l2 = 10\n",
    "\n",
    "# Specify K for K-fold cross validaton\n",
    "num_folds = 5\n",
    "\n",
    "# Specify confidence level ( < 1)\n",
    "cf_lvl = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fae9095-9818-42e1-a7ce-9f6340138c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels, test_images, test_labels, image_shape = util.get_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81bd046f-578c-4228-8a3b-ac59f2b50cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_drop(\n",
    "    filter_nos=[32, 32, 32],\n",
    "    filter_size=(3, 3),\n",
    "    dense_layers=[64],\n",
    "    input_shape=image_shape,\n",
    "    patience=5,\n",
    "    dropoutRate=0.1,\n",
    "    output_length=100\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        filter_nos (tuple): number of filters in each Conv2D layer\n",
    "        filter_size (tuple): size of Conv2D filters. Filters are assumed to have uniform sizes across layers.\n",
    "        input_shape (tuple): shape of the input of the first layer\n",
    "        dense_layer (tuple): number of hidden units in each Dense layer except the output layer. Output layer is hardcoded to the number of classes.\n",
    "        patience (integer): number of epochs of no improvement until early stop triggers.\n",
    "        dropoutRate (double < 1): rate of value drop\n",
    "        output_length (integer): number of classes for output\n",
    "    \"\"\"\n",
    "    # Would include a dropout parameter, but wasn't absolutely sure where those would be, though I would assume closer to the start.\n",
    "\n",
    "    model = models.Sequential()\n",
    "    callback = callbacks.EarlyStopping(monitor='loss',patience=patience) # EarlyStopping \n",
    "\n",
    "    for i, filter_no in enumerate(filter_nos):\n",
    "        if i == 0:\n",
    "            # first Conv2D requires input_shape\n",
    "            model.add(\n",
    "                layers.Conv2D(\n",
    "                    filter_no, filter_size, activation=\"relu\", input_shape=input_shape, kernel_regularizer='l2'\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            model.add(layers.Conv2D(filter_no, filter_size, activation=\"relu\"))\n",
    "\n",
    "        if i + 1 < len(filter_nos):\n",
    "            model.add(\n",
    "                layers.MaxPooling2D((2, 2))\n",
    "            )  # add MaxPooling layer to all but the last convolutional stack\n",
    "            model.add(\n",
    "                layers.Dropout(rate=dropoutRate)\n",
    "            )  \n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    for dense_layer in dense_layers:\n",
    "        model.add(layers.Dense(dense_layer, activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.Dense(output_length))  # output layer\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a7e80c8-4e1b-4815-8903-c10834653976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_l2(\n",
    "    filter_nos=[32, 32, 32],\n",
    "    filter_size=(3, 3),\n",
    "    dense_layers=[64],\n",
    "    input_shape=image_shape,\n",
    "    patience=5,\n",
    "    l2param=0.1,\n",
    "    output_length=100\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        filter_nos (tuple): number of filters in each Conv2D layer\n",
    "        filter_size (tuple): size of Conv2D filters. Filters are assumed to have uniform sizes across layers.\n",
    "        input_shape (tuple): shape of the input of the first layer\n",
    "        dense_layer (tuple): number of hidden units in each Dense layer except the output layer. Output layer is hardcoded to the number of classes.\n",
    "        patience (integer): number of epochs of no improvement until early stop triggers.\n",
    "        l2param (double < 1): param given to L2\n",
    "        output_length (integer): number of classes given to output\n",
    "    \"\"\"\n",
    "    # Would include a dropout parameter, but wasn't absolutely sure where those would be, though I would assume closer to the start.\n",
    "\n",
    "    model = models.Sequential()\n",
    "    regularizers.L2(l2=l2param) #L2\n",
    "    callback = callbacks.EarlyStopping(monitor='loss',patience=patience) # EarlyStopping \n",
    "\n",
    "    for i, filter_no in enumerate(filter_nos):\n",
    "        if i == 0:\n",
    "            # first Conv2D requires input_shape\n",
    "            model.add(\n",
    "                layers.Conv2D(\n",
    "                    filter_no, filter_size, activation=\"relu\", input_shape=input_shape, kernel_regularizer='l2'\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            model.add(layers.Conv2D(filter_no, filter_size, activation=\"relu\", kernel_regularizer='l2'))\n",
    "\n",
    "        if i + 1 < len(filter_nos):\n",
    "            model.add(\n",
    "                layers.MaxPooling2D((2, 2))\n",
    "            )  # add MaxPooling layer to all but the last convolutional stack\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    for dense_layer in dense_layers:\n",
    "        model.add(layers.Dense(dense_layer, activation=\"relu\", kernel_regularizer='l2'))\n",
    "\n",
    "    model.add(layers.Dense(output_length))  # output layer\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "793f5d29-2a4d-4899-aa71-9122eec18e89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stopper = callbacks.EarlyStopping(monitor='val_accuracy', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260b5eac-72df-40be-b78b-201cd3037a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropoff\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 22:57:09.863136: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :\n",
      "2024-07-10 22:57:09.863216: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-07-10 22:57:09.863233: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c3618.swan.hcc.unl.edu): /proc/driver/nvidia/version does not exist\n",
      "2024-07-10 22:57:09.863485: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-10 22:57:09.900260: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2294510000 Hz\n",
      "2024-07-10 22:57:09.900465: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e181a619d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-10 22:57:09.900486: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x145c578310d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x145c578310d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 4.1752 - accuracy: 0.0600\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 3.6233 - accuracy: 0.1461\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 3.3237 - accuracy: 0.1990\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 3.1317 - accuracy: 0.2366\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 2.9945 - accuracy: 0.2648\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 2.8930 - accuracy: 0.2831\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 2.8087 - accuracy: 0.2991\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 2.7383 - accuracy: 0.3129\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 2.6765 - accuracy: 0.3284\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 2.6229 - accuracy: 0.3385\n",
      "WARNING:tensorflow:From /common/cse478/shared/envs/hw/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x145c0cd3d280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x145c0cd3d280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x145c0c0520d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x145c0c0520d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 692/1250 [===============>..............] - ETA: 11s - loss: 4.2976 - accuracy: 0.0441"
     ]
    }
   ],
   "source": [
    "print(\"Dropoff\\n\")\n",
    "classifier_drop = KerasClassifier(\n",
    "    create_model_drop,\n",
    "    filter_nos=(32, 64, 64),\n",
    "    filter_size=(3, 3),\n",
    "    dense_layers=(64,),\n",
    "    input_shape=image_shape,\n",
    "    patience=5,\n",
    "    dropoutRate=0.1,\n",
    "    output_length=100,\n",
    "    epochs=epochs_drop,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "dropScores = cross_validate(\n",
    "    estimator=classifier_drop, X=train_images, y=train_labels, cv=num_folds, scoring=make_scorer(accuracy_score)\n",
    ")\n",
    "print(dropScores[\"test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602d2cd2-0948-40a2-ae78-41fc2a744971",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"L2\\n\")\n",
    "classifier_l2 = KerasClassifier(\n",
    "    create_model_l2,\n",
    "    filter_nos=(32, 64, 64),\n",
    "    filter_size=(3, 3),\n",
    "    dense_layers=(64,),\n",
    "    input_shape=image_shape,\n",
    "    patience=5,\n",
    "    l2param=0.1,\n",
    "    output_length=100,\n",
    "    epochs=epochs_l2,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "l2Scores = dropScores = cross_validate(\n",
    "    estimator=classifier_l2, X=train_images, y=train_labels, cv=num_folds, scoring=make_scorer(accuracy_score)\n",
    ")\n",
    "print(l2Scores[\"test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d420746-bf13-407b-adf6-afee19d10107",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = util.diff_scores(dropScores['test_score'], l2Scores['test_score'])\n",
    "mean_diff = np.mean(diff)\n",
    "std_diff = np.std(diff, ddof=(num_folds-1))\n",
    "#cf_interval_heart = t.interval(cf_lvl, df, mean_diff_heart, std_diff_heart/np.sqrt(num_folds))\n",
    "cf_interval_heart = t.interval(cf_lvl, (num_folds-1), loc=mean_diff, scale=std_diff/np.sqrt(num_folds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python CSE478",
   "language": "python",
   "name": "cse478-hw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
